diff -Nurd cmd/generate_repo_config/generate_repo_config.go cmd/generate_repo_config/generate_repo_config.go
--- cmd/generate_repo_config/generate_repo_config.go	2020-12-23 13:58:38.000000000 -0500
+++ cmd/generate_repo_config/generate_repo_config.go	2021-01-15 23:39:02.075431840 -0500
@@ -96,8 +96,9 @@
 	for _, r := range sortedFiles {
 		for _, d := range r.Directives {
 			// skip repository_macro directives, because for the repo config we flatten
-			// macros into one file
-			if d.Key != "repository_macro" {
+			// macros into one file. skip repository directives because they are merged
+			// into repos already.
+			if d.Key != "repository_macro" && d.Key != "repository" {
 				buf.WriteString("# gazelle:" + d.Key + " " + d.Value + "\n")
 			}
 		}
@@ -109,6 +110,9 @@
 		if rsrc.Kind() == "go_repository" {
 			rdst = rule.NewRule("go_repository", rsrc.Name())
 			rdst.SetAttr("importpath", rsrc.AttrString("importpath"))
+			if namingConvention := rsrc.AttrString("build_naming_convention"); namingConvention != "" {
+				rdst.SetAttr("build_naming_convention", namingConvention)
+			}
 		} else if rsrc.Kind() == "http_archive" && rsrc.Name() == "io_bazel_rules_go" {
 			rdst = rule.NewRule("http_archive", "io_bazel_rules_go")
 			rdst.SetAttr("urls", rsrc.AttrStrings("urls"))
diff -Nurd config/constants.go config/constants.go
--- config/constants.go	2020-12-23 13:58:38.000000000 -0500
+++ config/constants.go	2021-01-15 23:39:02.075431840 -0500
@@ -24,4 +24,8 @@
 	// GazelleImportsKey is an internal attribute that lists imported packages
 	// on generated rules. It is replaced with "deps" during import resolution.
 	GazelleImportsKey = "_gazelle_imports"
+
+	// GazelleDirectiveKey is an internal attribute that is set to true on rules
+	// which were produced by a gazelle:repository directive.
+	GazelleFromDirectiveKey = "_gazelle_from_directive"
 )
diff -Nurd repo/BUILD.bazel repo/BUILD.bazel
--- repo/BUILD.bazel	2020-12-23 13:58:38.000000000 -0500
+++ repo/BUILD.bazel	2021-01-15 23:39:02.083432022 -0500
@@ -9,6 +9,7 @@
     importpath = "github.com/bazelbuild/bazel-gazelle/repo",
     visibility = ["//visibility:public"],
     deps = [
+        "//config",
         "//label",
         "//pathtools",
         "//rule",
diff -Nurd repo/repo.go repo/repo.go
--- repo/repo.go	2020-12-23 13:58:38.000000000 -0500
+++ repo/repo.go	2021-01-15 23:39:02.083432022 -0500
@@ -30,6 +30,7 @@
 	"path/filepath"
 	"strings"
 
+	"github.com/bazelbuild/bazel-gazelle/config"
 	"github.com/bazelbuild/bazel-gazelle/rule"
 )
 
@@ -71,65 +72,94 @@
 func ListRepositories(workspace *rule.File) (repos []*rule.Rule, repoFileMap map[string]*rule.File, err error) {
 	repoIndexMap := make(map[string]int)
 	repoFileMap = make(map[string]*rule.File)
-	for _, repo := range workspace.Rules {
-		if name := repo.Name(); name != "" {
-			repos = append(repos, repo)
-			repoFileMap[name] = workspace
-			repoIndexMap[name] = len(repos) - 1
-		}
-	}
-	extraRepos, err := parseRepositoryDirectives(workspace.Directives)
+
+	defs, err := parseRepositoryDirectives(workspace, true)
 	if err != nil {
 		return nil, nil, err
 	}
-	for _, repo := range extraRepos {
-		if i, ok := repoIndexMap[repo.Name()]; ok {
-			repos[i] = repo
-		} else {
+
+	for _, r := range defs {
+		repo := r.repo
+		file := r.file
+
+		if repo.Name() == "" {
+			continue
+		}
+		name := repo.Name()
+		i, ok := repoIndexMap[name]
+		if !ok {
+			// This name has not been seen before, append it
 			repos = append(repos, repo)
+			repoFileMap[name] = file
+			repoIndexMap[name] = len(repos) - 1
+			continue
 		}
-		repoFileMap[repo.Name()] = workspace
+
+		// We have a duplicate declaration of this name. The rest of this logic determines which one we want to keep.
+		other := repos[i]
+
+		if isFromDirective(other) && !isFromDirective(repo) {
+			// Directives are always preferred
+			continue
+		}
+
+		if repoFileMap[name] == file && repo.Chunk() > 0 && other.Chunk() > 0 {
+			// These are two rule definitions from the same chunked file
+			if other.Chunk() < repo.Chunk() {
+				// The existing definition occurred in an earlier chunk, and has therefore been frozen.
+				// Bazel will ignore the new definition, so we will too.
+				continue
+			}
+		}
+
+		// Because parseRepositoryDirectives preserves ordering, repo comes after other, so it overrides it.
+		repos[i] = repo
+		repoFileMap[name] = file
 	}
 
-	for _, d := range workspace.Directives {
+	return repos, repoFileMap, nil
+}
+
+type repoDef struct {
+	repo *rule.Rule
+	file *rule.File
+}
+
+func isFromDirective(repo *rule.Rule) bool {
+	b, ok := repo.PrivateAttr(config.GazelleFromDirectiveKey).(bool)
+	if !ok {
+		return false
+	}
+	return b
+}
+
+func parseRepositoryDirectives(file *rule.File, recursive bool) (repos []repoDef, err error) {
+	for _, repo := range file.Rules {
+		repos = append(repos, repoDef{repo, file})
+	}
+
+	for _, d := range file.Directives {
 		switch d.Key {
 		case "repository_macro":
+			if !recursive {
+				continue
+			}
 			f, defName, err := parseRepositoryMacroDirective(d.Value)
 			if err != nil {
-				return nil, nil, err
+				return nil, err
 			}
-			f = filepath.Join(filepath.Dir(workspace.Path), filepath.Clean(f))
+			f = filepath.Join(filepath.Dir(file.Path), filepath.Clean(f))
 			macroFile, err := rule.LoadMacroFile(f, "", defName)
 			if err != nil {
-				return nil, nil, err
-			}
-			for _, repo := range macroFile.Rules {
-				if name := repo.Name(); name != "" {
-					repos = append(repos, repo)
-					repoFileMap[name] = macroFile
-					repoIndexMap[name] = len(repos) - 1
-				}
+				return nil, err
 			}
-			extraRepos, err = parseRepositoryDirectives(macroFile.Directives)
+
+			// Currently, we do not recursively process repository_macro directives.
+			extraRepos, err := parseRepositoryDirectives(macroFile, false)
 			if err != nil {
-				return nil, nil, err
-			}
-			for _, repo := range extraRepos {
-				if i, ok := repoIndexMap[repo.Name()]; ok {
-					repos[i] = repo
-				} else {
-					repos = append(repos, repo)
-				}
-				repoFileMap[repo.Name()] = macroFile
+				return nil, err
 			}
-		}
-	}
-	return repos, repoFileMap, nil
-}
-
-func parseRepositoryDirectives(directives []rule.Directive) (repos []*rule.Rule, err error) {
-	for _, d := range directives {
-		switch d.Key {
+			repos = append(repos, extraRepos...)
 		case "repository":
 			vals := strings.Fields(d.Value)
 			if len(vals) < 2 {
@@ -137,6 +167,7 @@
 			}
 			kind := vals[0]
 			r := rule.NewRule(kind, "")
+			r.SetPrivateAttr(config.GazelleFromDirectiveKey, true)
 			for _, val := range vals[1:] {
 				kv := strings.SplitN(val, "=", 2)
 				if len(kv) != 2 {
@@ -147,7 +178,7 @@
 			if r.Name() == "" {
 				return nil, fmt.Errorf("failure parsing repository: %s, expected a name attribute for the given repository", d.Value)
 			}
-			repos = append(repos, r)
+			repos = append(repos, repoDef{r, file})
 		}
 	}
 	return repos, nil
diff -Nurd rule/rule.go rule/rule.go
--- rule/rule.go	2020-12-23 13:58:38.000000000 -0500
+++ rule/rule.go	2021-01-15 23:39:02.083432022 -0500
@@ -235,13 +235,30 @@
 }
 
 func scanExprs(defName string, stmt []bzl.Expr) (rules []*Rule, loads []*Load, fn *bzl.DefStmt) {
+	// In most bazel files, there is a rule that load() statements must come
+	// at the top of the file. There is one exception to this rule: WORKSPACE
+	// is split into a sequence of chunks, each of which starts with load()
+	// statements. This chunking is used to determine which definition wins,
+	// when duplicates occur.
+	// We track it here and record which chunk each rule appeared in.
+	inLoadSection := false
+	// We start from 1, so that default 0 values indicate a rule isn't from a chunked file
+	chunk := 1
+
 	for i, expr := range stmt {
+		if _, ok := expr.(*bzl.LoadStmt); ok {
+			inLoadSection = true
+		} else if inLoadSection {
+			// We just saw a non-load statement, so we're entering a new chunk
+			chunk++
+			inLoadSection = false
+		}
 		switch expr := expr.(type) {
 		case *bzl.LoadStmt:
 			l := loadFromExpr(i, expr)
 			loads = append(loads, l)
 		case *bzl.CallExpr:
-			if r := ruleFromExpr(i, expr); r != nil {
+			if r := ruleFromExpr(i, chunk, expr); r != nil {
 				rules = append(rules, r)
 			}
 		case *bzl.DefStmt:
@@ -422,7 +439,7 @@
 }
 
 type stmt struct {
-	index                      int
+	index, chunk               int
 	deleted, inserted, updated bool
 	comments                   []string
 	commentsUpdated            bool
@@ -435,6 +452,11 @@
 // rules, this is the index of the original statement.
 func (s *stmt) Index() int { return s.index }
 
+// Chunk returns the index for the chunk of the file where this statement
+// occurred. This will be 0 if the rule did not come from a chunked file,
+// and 1 in any starlark file other than WORKSPACE.
+func (s *stmt) Chunk() int { return s.chunk }
+
 // Delete marks this statement for deletion. It will be removed from the
 // syntax tree when File.Sync is called.
 func (s *stmt) Delete() { s.deleted = true }
@@ -691,7 +713,7 @@
 	return r
 }
 
-func ruleFromExpr(index int, expr bzl.Expr) *Rule {
+func ruleFromExpr(index int, chunk int, expr bzl.Expr) *Rule {
 	call, ok := expr.(*bzl.CallExpr)
 	if !ok {
 		return nil
@@ -714,6 +736,7 @@
 	return &Rule{
 		stmt: stmt{
 			index:    index,
+			chunk:    chunk,
 			expr:     call,
 			comments: commentsFromExpr(expr),
 		},
